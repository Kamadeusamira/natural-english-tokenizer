\doxysection{statement.\+Statement\+\_\+\+Tokenizer Class Reference}
\label{classstatement_1_1_statement___tokenizer}\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}


This is the base class of tokenization system.  


Inheritance diagram for statement.\+Statement\+\_\+\+Tokenizer\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classstatement_1_1_statement___tokenizer}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
None \textbf{ \+\_\+\+\_\+init\+\_\+\+\_\+} (self, str text)
\begin{DoxyCompactList}\small\item\em It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. \end{DoxyCompactList}\item 
def \textbf{ statements} (self)
\item 
def \textbf{ words} (self)
\item 
str \textbf{ \+\_\+\+\_\+str\+\_\+\+\_\+} (self)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
This is the base class of tokenization system. 

Definition at line \textbf{ 3} of file \textbf{ statement.\+py}.



\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\label{classstatement_1_1_statement___tokenizer_a6448646d7a8eac6ecdcf864ffedbc45e}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{\_\_init\_\_()}
{\footnotesize\ttfamily  None statement.\+Statement\+\_\+\+Tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{str}]{text }\end{DoxyParamCaption})}



It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. 


\begin{DoxyParams}{Parameters}
{\em str} & text \+: it is the gevin text on which the the class operates and yield the result to the client. \\
\hline
\end{DoxyParams}


Reimplemented in \textbf{ tokenizer.\+QTokenizer} \doxyref{}{p.}{classtokenizer_1_1_q_tokenizer_a19214c752c986e339bc4d3afb6053c36}.



Definition at line \textbf{ 6} of file \textbf{ statement.\+py}.



\doxysubsection{Member Function Documentation}
\mbox{\label{classstatement_1_1_statement___tokenizer_a46393ccff9b734f02abc536632515ffb}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!\_\_str\_\_@{\_\_str\_\_}}
\index{\_\_str\_\_@{\_\_str\_\_}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{\_\_str\_\_()}
{\footnotesize\ttfamily  str statement.\+Statement\+\_\+\+Tokenizer.\+\_\+\+\_\+str\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \textbf{ 44} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1_statement___tokenizer_a95805cd75ff6211b4ee440182f90a2d7}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!statements@{statements}}
\index{statements@{statements}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{statements()}
{\footnotesize\ttfamily def statement.\+Statement\+\_\+\+Tokenizer.\+statements (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of the statements derived from the inputed text.\end{DoxyVerb}
 

Definition at line \textbf{ 34} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1_statement___tokenizer_acd1864a3158a91d3ac21009aa3a8ca57}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!words@{words}}
\index{words@{words}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{words()}
{\footnotesize\ttfamily def statement.\+Statement\+\_\+\+Tokenizer.\+words (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \textbf{ 40} of file \textbf{ statement.\+py}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
statement.\+py\end{DoxyCompactItemize}
