{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\info 
{\title {\comment Natural English Tokenization  {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
1.0 \par
}}Natural English Tokenization}
{\comment Generated by doxygen 1.9.5.}
{\creatim \yr2022\mo11\dy22\hr14\min52\sec49}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt Natural English Tokenization}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version 1.0\par{\field\fldedit {\*\fldinst CREATEDATE \\*MERGEFORMAT}{\fldrslt Tue Nov 22 2022 }}\par
\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
natural-english-tokenizer{\tc \v natural-english-tokenizer}\par \pard\plain 
{\bkmkstart AAAAAAAAAR}
{\bkmkend AAAAAAAAAR}
\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid }

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Hierarchical Index\par \pard\plain 
{\tc \v Hierarchical Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class Hierarchy\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid This inheritance list is sorted roughly, but not completely, alphabetically:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
data.Dict_Data\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAD \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
statement.Statement_Tokenizer\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAG \\*MERGEFORMAT}{\fldrslt pagenum}}
{
\par
\pard\plain \s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
tokenizer.QTokenizer\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAM \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
}\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Index\par \pard\plain 
{\tc \v Class Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the classes, structs, unions and interfaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b data.Dict_Data} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This class takes care of the origine of the reference against which the tokonization will be performed })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAD \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b tokenizer.QTokenizer} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAM \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b statement.Statement_Tokenizer} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is the base class of tokenization system })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAG \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all documented files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b data.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b statement.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b tokenizer.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAC \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Documentation{\tc \v Class Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
data.Dict_Data Class Reference\par \pard\plain 
{\tc\tcl2 \v data.Dict_Data}
{\xe \v data.Dict_Data}
{\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This class takes care of the origine of the reference against which the tokonization will be performed. }}\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
None {\b __init__} (self, alphabet_letter="Q", dir="data")\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It fetches Data from a json dictionary saved in python and parses it for tokonization purpose. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b data} (self)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
converts all the sets in the __data private property for it to be conveniently be stored in json }{
}\par
}\par}
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This class takes care of the origine of the reference against which the tokonization will be performed. \par
}

{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
For this purpose, a json file containing most words of the English language is used as a reference. \par
}{
Definition at line {\b 4} of file {\b data.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v __init__\:data.Dict_Data}
{\xe \v data.Dict_Data\:__init__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 None data.Dict_Data.__init__ (  {\i self},   {\i alphabet_letter} = {\f2 "Q"},   {\i dir} = {\f2 "data"})}}
\par
{\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It fetches Data from a json dictionary saved in python and parses it for tokonization purpose. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i str} \cell }{Q alphabet_letter pecifies on which letter of the alphabet the the class should work from \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i str} \cell }{data reprents the directory in which the json files containing the documents are located \cell }
{\row }
}
}{
Definition at line {\b 9} of file {\b data.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v data\:data.Dict_Data}
{\xe \v data.Dict_Data\:data}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def data.Dict_Data.data (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
converts all the sets in the __data private property for it to be conveniently be stored in json }}\par
{
Definition at line {\b 50} of file {\b data.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
data.py\par
}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
tokenizer.QTokenizer Class Reference\par \pard\plain 
{\tc\tcl2 \v tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer}
{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
Inheritance diagram for tokenizer.QTokenizer:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classtokenizer_1_1_q_tokenizer.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
None {\b __init__} (self, str text)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
dict {\b get_listed_tokens} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
dict {\b get_tokens_with_number} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b get_total_word} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __str__} (self)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Tokenizes all english words that start with Q}
 \par
}{
Definition at line {\b 5} of file {\b tokenizer.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v __init__\:tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer\:__init__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 None tokenizer.QTokenizer.__init__ (  {\i self}, str  {\i text})}}
\par
{\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i str} \cell }{text : it is the gevin text on which the the class operates and yield the result to the client. \cell }
{\row }
}
}{
Reimplemented from {\b statement.Statement_Tokenizer} ({\i p.{\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAH \\*MERGEFORMAT}{\fldrslt pagenum}}}).}\par
{
Definition at line {\b 8} of file {\b tokenizer.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v __str__\:tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer\:__str__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str tokenizer.QTokenizer.__str__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Reimplemented from {\b statement.Statement_Tokenizer} ({\i p.{\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAG \\*MERGEFORMAT}{\fldrslt pagenum}}}).}\par
{
Definition at line {\b 60} of file {\b tokenizer.py}.}\par
}
{\xe \v get_listed_tokens\:tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer\:get_listed_tokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
  dict tokenizer.QTokenizer.get_listed_tokens (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAO}
{\bkmkend AAAAAAAAAO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid It just returns a dictionary of tokens with the keys representing the nine \par
fundamental types of the english words and the values being a list of such words found in \par
the _tokens property.}
 \par
}{
Definition at line {\b 42} of file {\b tokenizer.py}.}\par
}
{\xe \v get_tokens_with_number\:tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer\:get_tokens_with_number}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
dict tokenizer.QTokenizer.get_tokens_with_number (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAP}
{\bkmkend AAAAAAAAAP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid It just turns a dictionary of tokens with the keys representing the nine \par
fundamental types of the english words and the values being a total number of such words found in the \par
_tokens property.}
 \par
}{
Definition at line {\b 49} of file {\b tokenizer.py}.}\par
}
{\xe \v get_total_word\:tokenizer.QTokenizer}
{\xe \v tokenizer.QTokenizer\:get_total_word}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 int tokenizer.QTokenizer.get_total_word (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAQ}
{\bkmkend AAAAAAAAAQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 57} of file {\b tokenizer.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
tokenizer.py\par
}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement.Statement_Tokenizer Class Reference\par \pard\plain 
{\tc\tcl2 \v statement.Statement_Tokenizer}
{\xe \v statement.Statement_Tokenizer}
{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is the base class of tokenization system. }}\par
Inheritance diagram for statement.Statement_Tokenizer:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classstatement_1_1_statement___tokenizer.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
None {\b __init__} (self, str text)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b statements} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b words} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __str__} (self)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is the base class of tokenization system. \par
}{
Definition at line {\b 3} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v __init__\:statement.Statement_Tokenizer}
{\xe \v statement.Statement_Tokenizer\:__init__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 None statement.Statement_Tokenizer.__init__ (  {\i self}, str  {\i text})}}
\par
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i str} \cell }{text : it is the gevin text on which the the class operates and yield the result to the client. \cell }
{\row }
}
}{
Reimplemented in {\b tokenizer.QTokenizer} ({\i p.{\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAI \\*MERGEFORMAT}{\fldrslt pagenum}}}).}\par
{
Definition at line {\b 6} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v __str__\:statement.Statement_Tokenizer}
{\xe \v statement.Statement_Tokenizer\:__str__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str statement.Statement_Tokenizer.__str__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 44} of file {\b statement.py}.}\par
}
{\xe \v statements\:statement.Statement_Tokenizer}
{\xe \v statement.Statement_Tokenizer\:statements}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.Statement_Tokenizer.statements (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Returns a list of the statements derived from the inputed text.}
 \par
}{
Definition at line {\b 34} of file {\b statement.py}.}\par
}
{\xe \v words\:statement.Statement_Tokenizer}
{\xe \v statement.Statement_Tokenizer\:words}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.Statement_Tokenizer.words (  {\i self})}}
\par
{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 40} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
statement.py\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
data.py\par \pard\plain 
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 import} json\par
00002 {\cf17 import} os\par
00003 \par
00004 {\cf17 class }Dict_Data:\par
00005     {\cf22 """!This class takes care of the origine of the reference against which the tokonization will be }\par
00006 {\cf22     performed. For this purpose, a json file containing most words of the English language }{\cf19 is} used {\cf17 as} a reference.\par
00007     {\cf22 """}\par
00008 {\cf22 }\par
00009 {\cf22     }{\cf17 def }__init__(self, alphabet_letter="Q", dir="data") -> None:\par
00010         {\cf22 """!It fetches Data from a json dictionary saved in python and parses it for tokonization purpose}\par
00011 {\cf22             }{\cf21 @param} str Q alphabet_letter pecifies on which letter of the alphabet the the {\cf17 class }should work from\par
00012             {\cf21 @param} str data reprents the directory {\cf19 in} which the json files containing the documents are located\par
00013         {\cf22 """}\par
00014 {\cf22         self.__data = \{}\par
00015 {\cf22             "noun"}:set(), \par
00016             {\cf22 "pronoun"}:set(), \par
00017             {\cf22 "verb"}:set(),\par
00018             {\cf22 "article"}:set(),\par
00019             {\cf22 "adjective"}:set(),\par
00020             {\cf22 "adverb"}:set(),\par
00021             {\cf22 "preposition"}:set(),\par
00022             {\cf22 "conjunction"}:set(),\par
00023             {\cf22 "interjection"}:set()\par
00024         \}\par
00025         self.__letter= {\cf22 ""}.join([{\cf22 "D"}, alphabet_letter])\par
00026         self.__dir = dir\par
00027         self.__load_data()\par
00028 \par
00029     {\cf17 def }__load_data(self) -> None:\par
00030         {\cf22 """!Never call this method it is conviniently called at the proper moment at run time. }\par
00031 {\cf22         It loads data }{\cf17 from} a predifined dictionary saved {\cf19 in} json format {\cf19 and} structures it {\cf19 in} accordance {\cf17 with} the \par
00032         nine (9) fundamental types of the English language words{\cf22 """}\par
00033 {\cf22 }\par
00034 {\cf22         path = os.path.join(self.__dir, self.__letter)}\par
00035 {\cf22         path += ".json"}\par
00036         {\cf19 try}:\par
00037             {\cf17 with} open(path) {\cf17 as} file:\par
00038                 data = json.load(file)\par
00039             {\cf19 for} word, explanations {\cf19 in} data.items():\par
00040                 meanings = explanations.get({\cf22 "MEANINGS"}, \{\})\par
00041                 {\cf19 for} definition {\cf19 in} meanings.values():\par
00042                     {\cf19 if} definition:\par
00043                         fund_type = definition[0].lower()\par
00044                         {\cf19 if} fund_type {\cf19 in} self.__data:\par
00045                             self.__data[fund_type].add(word)\par
00046         {\cf19 except} FileNotFoundError {\cf17 as} e:\par
00047             print(e)\par
00048     \par
00049     {\cf21 @property}\par
00050     {\cf17 def }data(self):\par
00051         {\cf22 """!converts all the sets in the __data private property for it to be conveniently be stored in json"""}\par
00052 \par
00053         {\cf19 return} \{key:list(value) {\cf19 for} key, value {\cf19 in} self.__data.items()\}\par
00054         \par
00055 \par
00056 {\cf19 if} __name__ == {\cf22 "__main__"}:\par
00057     {\cf22 """!Testing"""}\par
00058     {\cf17 import} string\par
00059     A_Z = list(string.ascii_uppercase)\par
00060     os.makedirs({\cf22 "data_treamed"}, exist_ok={\cf17 True})\par
00061     {\cf19 for} letter {\cf19 in} A_Z:\par
00062         d_d = Dict_Data(alphabet_letter=letter)\par
00063         {\cf17 with} open({\cf22 "data_treamed/Bayi_"}+letter+{\cf22 ".json"}, {\cf22 "w"}) {\cf17 as} file:\par
00064             json.dump(d_d.data, file, indent=4)\par
00065     \par
00066 \par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement.py\par \pard\plain 
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 import} re\par
00002 \par
00003 {\cf17 class }Statement_Tokenizer:\par
00004     {\cf22 """!This is the base class of tokenization system. """}\par
00005     \par
00006     {\cf17 def }__init__(self, text:str) -> {\cf18 None}:\par
00007         {\cf22 """!}\par
00008 {\cf22         It abstracts the details of splitting the given text into tokens }{\cf19 and} let the client\par
00009         worry only about the results {\cf17 as} she {\cf19 or} he can get them though the statements property {\cf19 or} words property.\par
00010         {\cf21 @param} str text : it {\cf19 is} the gevin text on which the the {\cf17 class }operates and yield the result to the client.\par
00011         {\cf22 """}\par
00012 {\cf22         self.__statement_pattern = '[\\.!?]'}\par
00013         self.__word_regex = re.compile({\cf22 '[^a-zA-Z]'})\par
00014         self.__words = []\par
00015         text = re.sub({\cf22 r"\\s+"}, {\cf22 " "}, text)\par
00016         self._get_tokens(text)\par
00017         \par
00018     {\cf17 def }_get_tokens(self, text:str) -> {\cf18 None}:\par
00019         {\cf22 """!This method Would be called at the appropriate moment at run time. It will split the given text in }\par
00020 {\cf22         statements }{\cf19 and} then {\cf19 in} words so {\cf17 as} to make the words available {\cf19 for} the child classes that are going \par
00021         to parse them.\par
00022         {\cf21 @param} str text : it {\cf19 is} the gevin text on which the the method operates.{\cf22 """}\par
00023 {\cf22 }\par
00024 {\cf22         }{\cf19 if} {\cf19 not} text.strip():\par
00025             {\cf19 return}\par
00026         self.__statements = re.split(self.__statement_pattern, text)\par
00027         {\cf19 if} {\cf19 not} self.__statements[-1]:\par
00028             self.__statements.pop()\par
00029         {\cf19 for} statement {\cf19 in} self.__statements:\par
00030             self.__words.extend(\par
00031                 [self.__word_regex.sub({\cf22 ""}, word.upper()) {\cf19 for} word {\cf19 in} statement.split({\cf22 " "}) {\cf19 if} word.strip()]\par
00032             )\par
00033     {\cf21 @property}\par
00034     {\cf17 def }statements(self):\par
00035         {\cf22 """Returns a list of the statements derived from the inputed text."""}\par
00036 \par
00037         {\cf19 return} self.__statements\par
00038 \par
00039     {\cf21 @property}\par
00040     {\cf17 def }words(self):\par
00041         {\cf22 "Returns a list of single words that can easily be further prossessed."}\par
00042         {\cf19 return} self.__words\par
00043     \par
00044     {\cf17 def }__str__(self) -> str:\par
00045        repr = [f{\cf22 "statement \{n\} -> \{s\}"} {\cf19 for} n, s {\cf19 in} enumerate(self.__statements, 1)]\par
00046        {\cf19 return} {\cf22 "\\n"}.join(repr)\par
00047 \par
00048 \par
00049 {\cf19 if} __name__ == {\cf22 "__main__"}:\par
00050     {\cf22 """! @test"""}\par
00051     s_t = Statement_Tokenizer({\cf22 "Qatar 2022. I went, to be : qualified. Question? not Question"})\par
00052     print(s_t.statements)\par
00053     print(s_t.words)\par
00054     print(s_t)\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
tokenizer.py\par \pard\plain 
{\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 from} statement {\cf17 import} Statement_Tokenizer\par
00002 {\cf17 from} data {\cf17 import} Dict_Data\par
00003 \par
00004 \par
00005 {\cf17 class }QTokenizer(Statement_Tokenizer):\par
00006     {\cf22 """Tokenizes all english words that start with Q"""}\par
00007     \par
00008     {\cf17 def }__init__(self, text:str) -> {\cf18 None}:\par
00009         super().__init__(text)\par
00010         ref = Dict_Data({\cf22 "Q"})\par
00011         self.__ref = ref.data\par
00012         self.__tokens = \{\par
00013             {\cf22 "noun"}:[], \par
00014             {\cf22 "pronoun"}:[], \par
00015             {\cf22 "verb"}:[],\par
00016             {\cf22 "article"}:[],\par
00017             {\cf22 "adjective"}:[],\par
00018             {\cf22 "adverb"}:[],\par
00019             {\cf22 "preposition"}:[],\par
00020             {\cf22 "conjunction"}:[],\par
00021             {\cf22 "interjection"}:[],\par
00022             {\cf22 "no_match"}:[]\par
00023         \}\par
00024         self.__parse_words()\par
00025 \par
00026     \par
00027     {\cf17 def }__parse_words(self):\par
00028         {\cf22 """This method will be called at the appropria moment at run time"""}\par
00029         words = list(filter({\cf17 lambda} w: w.startswith({\cf22 "Q"}), self.words))\par
00030         {\cf19 for} word {\cf19 in} words:\par
00031             {\cf19 for} key, value {\cf19 in} self.__ref.items():\par
00032                 \par
00034                 {\cf19 if} word {\cf19 in} value:\par
00035                     self.__tokens[key].append(word)\par
00036                     {\cf19 break}\par
00037             {\cf19 else}:\par
00038                 self.__tokens[{\cf22 "no_match"}].append(word)\par
00039 \par
00040     \par
00041 \par
00042     {\cf17 def }get_listed_tokens(self) ->  dict:\par
00043         {\cf22 """It just returns a dictionary of tokens with the keys representing the nine }\par
00044 {\cf22         fundamental types of the english words }{\cf19 and} the values being a list of such words found {\cf19 in} \par
00045         the _tokens property.{\cf22 """}\par
00046 {\cf22 }\par
00047 {\cf22         }{\cf19 return}  self.__tokens\par
00048 \par
00049     {\cf17 def }get_tokens_with_number(self)->dict:\par
00050         {\cf22 """It just turns a dictionary of tokens with the keys representing the nine }\par
00051 {\cf22         fundamental types of the english words }{\cf19 and} the values being a total number of such words found {\cf19 in} the \par
00052         _tokens property.{\cf22 """}\par
00053 {\cf22 }\par
00054 {\cf22         }{\cf19 return} \{key : len(value)  {\cf19 for} key, value {\cf19 in} self.__tokens.items()\par
00055         \}\par
00056 \par
00057     {\cf17 def }get_total_word(self) -> int:\par
00058         {\cf19 return} sum(self.get_tokens_with_number().values())\par
00059 \par
00060     {\cf17 def }__str__(self) -> str:\par
00061         {\cf19 return} super().__str__()\par
00062 \par
00063 {\cf19 if} __name__ == {\cf22 "__main__"}:\par
00064     q_t = QTokenizer({\cf22 """Cameroon is qualified for the Qatar 2022 world cup of nations. Did you know Qaddafi went }\par
00065 {\cf22     to heaven? Indeed that }{\cf19 is} {\cf19 not} questionable! Quantum coding {\cf19 is} quickly gaining popularity. Queenly follow the \par
00066     QTokenizer module. Keep quiete. Software engineer don{\cf22 't quarrel like philosophers but they too have quote.""")}\par
00067 {\cf22     print(q_t)}\par
00068 {\cf22     print(q_t.get_listed_tokens())}\par
00069 {\cf22     print(q_t.get_tokens_with_number())}\par
00070 {\cf22     print("Total words: "}, q_t.get_total_word())\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
